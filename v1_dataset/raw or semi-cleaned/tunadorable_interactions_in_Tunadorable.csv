id,response,message
1154526028983701525,hahaha full send or don't send at all,"dude this is the level of ambition im on, although im not nearly as dedicated as u"
1154800060131967106,ooof that was not easy to listen to please call me out if i ever decide to chew with my mouth open or even eat on camera,https://youtu.be/vn9Dq24RDn8?si=zPQlj3CHpf19676x
1154800311639224400,"yeah fs a good intro call to action for a science of intelligence. pretty sure i saw that debate bw him and Eliezer. Not too fond of this guy's vibe in general tho, I'm more of a Joscha Bach fan",he makes some interesting points in this but nothing to take too seriously
1155897740493070346,"i‚Äôve got a bunch of channel improvements starting this week to make me seem more like a regular organized youtuber, this is one of them",@Tunadorable you should add the discord to your video descriptions
1155898043510558782,# yo no way,"wait can i use **markdown** syntax _here_ 
- lets see"
1155898200918609990,"i am become change, confuser of subscribers","Didn't you say you kinda like the idea of people having to click and find the discord link as opposed to joining after a small binge?

Just curious if this opinion has changed. I don't personally mind either way."
1155912751273746504,"The nice thing with Obsidian being proprietary is that they use open-source data formats, so even if the company went to shit the dedicated community would probably just create an amazing (hopefully fully open-source) replacement","I've been a note-taking nomad as of late üò• this video kinda describes my problem actually:
https://youtu.be/XRpHIa-2XCE?si=FIwnMrKvb_6Mswaw

Also this guy is super entertaining. But like my issue with obsidian is that it's proprietary. Although it is a great piece of software.

I probably should just stop worrying and use obsidian."
1155916441917337792,Yeah idk but I'm just betting on the fact that I'm not the first person to think of it and I wouldn't be the best person to code it up so I'll wait until it's created for me,"Nice idea. I wonder how hard this would actually be with a combination of gpt-3.5 fine-tunings, and vector-db driving RAG ü§î"
1155921732926984212,same hype to find more likeminded people,"bro are you literally me? i want to learn all of these, i just dont have 1/10th of the discipline to do it rn. with your determination im confident you'll at the very minimum be very knowledgeable in all of them. i have been thinking a lot recently about what if the greatest minds who have ever lived wouldve acomplished if they had the resources or starting point we have today, or even if just a regular person consumed benefitting content instead of purely entertainment. im glad ive found some likeminded who got better attitudes than me"
1155955470142541875,"The recommendations thing is a good idea. I have a general prompt that basically just tells it 1) to output al lmath in LaTeX rather than markdown and 2) that if I ask ""what is x"" and x is an ambiguous term that could be from multiple fields, assume by default I'm referring to AI/ML/math. Other than that it doesn't change responses too much.",Do you guys tailor ChatGPT custom instructions to help you grow in certain areas? I'm wondering if anyone has any insights for their custom instructions. One thing I do is I've told it to start recommending philosophers to read up on and different concepts I might be interested in based on our conversation. I've done a similar thing with learning spanish.
1156240162754404404,"yeah if you define AGI as just taking away an irreplaceable number of jobs then I think GPT-N will be AGI. But if you define it as conscious, taking all jobs, or hitting the singularity then no",i get it why people are scared and the jobs stuff is really soemthing to worry about but i have hope that humans would figure something out
1156241164266127553,I think if you scanned my brain and uploaded it to a computer then computer Evin would not listen to your commands,i am talking about conscious AI @Tunadorable dare i say i think AI in the form of a tool as we use it now will not be conscious  like imagine i find a way to use your brain power and make first human neural network  right i can do same stuff as you do but its a tool now and it will only listen to me would  you consider that system conscious ?? i think the autonomy we have drives our ability to reason as well
1156243198960738448,Bilal the arbiter of who is and is not allowed to interact with the coming superintelligence,"its just a thought process i came up to ask people , if they respond poorly i am never having ai talk with them"
1156243384403497193,am I correct in thinking that you're a dualist then?,"> that AGI would just be me and I'd be able to imagine giving you the middle finger
> 
> see i think that won't even be you its just your brain and not your conscious being its just a tool at that point and therefore not an AGI"
1156244615997960213,I mean sure you could argue that I'd need the rest of my nervous system and even teh computation done by individual tissue cells but yeah I think I am the computation that creates the self-aware sense of myself,what made you think that your brain is you
1156246672876245043,If I'm right that there is a such thing as different flavors of intelligence/consciousness then yes. But I also think consciousness is a particularly good learning algorithm so there's a chance it might be necessary to really make intelligence *general*,but AGI can be AGI and not conscious
1156247914486697984,"I think in the free will argument of determinism vs randomness people are asking the wrong questions and searching for the wrong thing. The introduction of the idea of determinism robbed people of a sense of agency, and those who couldn't just ignore it started to search out randomness as the source of their free will with stuff like the microtubule quantum theory. But randomness isn't free will, it's just randomness which is equally ""bad"" as determinism in this mindset. What you have to do is change your mindset. If you think of *yourself* as separate from the physical processes that *deterministically* compose you then yes those processes are deciding for you and therefore you have no free will. But if you identify with those deterministic processes as a part of yourself then you are the one deciding those processes, and hence you have free will. However this does require that you essentially keep abstracting out and start to identify with the entire universe, which most people are not willing to do","conscioussness is definitely not deterministic. because if it is, why couldnt humans choises exist as a DETERMINISTIC computation in the brain instead of a lived experience"
1156249574923583508,"To that I'd say that it's wrong to think if *it* as separate from *us*. Separateness/duality/otherness is an illusion. Intelligence is defined recursively. The sub-circuit of the neurons in your stomach are not separate from your intelligence, they are a part of your intelligence. In the same way, to the extent that any computer program exhibits intelligence it is not a separate intelligence, it is a part of the intelligence of its creator.

But yet again as with all my viewpoints, now we have to keep going up the chain and say that all intelligences are connected into one single *universe* intelligence","By the term ""Artificial General Intelligence"", meaning something that has the intelligence of a human being, I do think that it can exist without consciousness.

I think the learning algorithm idea has weight to it. However, I do wonder if it's necessary if humans are the ones helping the AI learn. We've gotten it to this point, and to some degree I'd say it's intelligent. It can solve problems and impose will on the world.

Past a certain point of advancement it will also be able to create more intelligent versions of itself. Simply by mimicking human intelligence I think a generally intelligent system could emerge.

In other words maybe it could be intelligent, because we're the ones providing the consciousness to jump start it?"
1156250978408992809,"You should look into chaos theory. There's a good intuitive book by I think James Gleck or Gleick. Basically deterministic phenomena can also be just as unpredictable as random phenomena, it's a natural result of differential equations. Also related to the concept of emergence which I think I have a video on","I like this. What I'd say is that this ""source of randomness"" is the wrong way to find an answer. You're right about randomness being a bad way to look at it. However, what I've always been much more interested in was ""unpredictability"", rather than randomness.

If the way that quantum phenomena work makes them inherently unpredictable, then I think that there's an argument against a deterministic view there. The reason being that consciousness and therefore will could be an abstraction on top of those phenomena.

So I think we pretty much agree here. The idea that we're kinda a part of the universe's will and not simply a slave to its deterministic processes is a much better mindset than trying to find some randomness.

I think we can sort of see that ""randomness"", as actually just unpredictability, and potentially evidence of that will."
1156251795933376693,yeah i try to consciously think about at what level i want to understand something. yt videos for stuff i want to be vaguely aware of jic i need to look into it at some point and then all the way to math proofs if they‚Äôre available for something i need to use in order to facilitate the creation of an idea i‚Äôm pursuing,"That sounds great. I need to read more, I have quite the backlog ü§£

I watch a ton of YouTube videos because they feel easier to digest than books though ü§î. At least for concepts... I think."
1156257690968928286,i‚Äôll add any channel topic i have no clue how discord works or how it‚Äôs supposed to work,"@Tunadorable could we have a channel for media recommendations? Like YT videos, articles, etc. Maybe I'm missing something or it's not the point of the server ü§∑‚Äç‚ôÇÔ∏è"
1156259075387039855,yes i only brought up randomness because it‚Äôs the only alternative i‚Äôve heard proposed other than souls,"had to brb for a sec. you have a very good point, but thats assuming that non-determinism is just purely randomness. im open to the idea that non-deterministic processes play a role in consciousness, though not necessarily like Penrose's theory. i personally think free will inherently needs to not be deterministic. i think these questions are important because without it we wont ever be able to know if consciousness is computationally feasible"
1156259177723875439,what‚Äôs the computer requirement tho?,some guy ported it to tensorflow and its 70 times faster
1156260812697108490,this is the chad i made the channel for,What's up everyone
1156262196347682917,MY MAN DONALD,new whip
1156264040482480199,i still don‚Äôt understand what a Chad is but glad to hear i‚Äôm not the top one,actual chad chanel bit @Tunadorable is still top not even a chad actually a THAD
1156497769704456235,"Just finished my application. Highly doubt I get it, the form was definitely catered towards academics and towards research interests that are nowhere near my own. Fingers crossed tho cuz I'm close to broke","@Tunadorable i was reading on open ai's blog that you can get free access to open ai's api if you are independent researcher or something and there is this form filling and approving process to get it but i will shoot the shot https://openai.smapply.org/prog/openai_researcher_access_program/#:~:text=We're%20interested%20in%20supporting,please%20apply%20for%20API%20credits."
1156498179836100668,nah acid and narcissism did that,@Tunadorable do you think studying maths made you more smart /creative
1156889068060291083,I have not. I get distracted pretty easily but the goal rn is to start diving deeper into theory rather than application so I don't think i'll be able to give it much thought for awhile,@Tunadorable have you been keeping up with meta's image to 3d and SAM research  i think technically they did really well
1158798437605720176,are you referncing the fact that i literally did that with one of the earlier vids? üòÇ,we dont want people with 2 seconds of attenion span evin would have to put a subway surfers gameplay with ai summaries to grab attention
1158800374656929822,i didn't know how to exit vim when it came up in my terminal,wait why
1158801715601084568,i mean yeah i googled or chatGPT'd or something but still there was an initial moment of panic where i didn't know what was happening cuz i had no clue why the terminal had even changed so I didn't know what to ask,you didnt google the thing
1158819246499962910,"yo let's try and avoid politics pls. I'm new to discord but i got into it knowing it didn't have the best reputation and i'd prefer to avoid that altogether & stick to coding, AI, math, consciousness, etc",rust people are like lgbtq people
1158828435431510096,fs I don't agree with him on basically anyting that I've heard but an interview with Connor is what convinced me that I needed to get into AI so that nerd with terrible hair has a special place in my heart,"I like ""Check out this open source 20b model"" Connor a lot better than ""AI will kill us all if you don't limit GPUs even though I'm hoarding H100s"" Connor Leahy (I know that's going back into politics, but it's relevant to us and... Like, you first, dude)."
1158833361259864075,"yeah i agree, i prefer to say that i disagree rather than accuse of evil. My best reading of sam altman is that despite some iffy moves, he does legitimately think GPT-N could wake up and get out of hand, which is reasonable. But he's moreso concerned about the short-term in which one of their models teaching a terrorist how to build a bomb or something could ruin the company and by extension his chances at becoming the daddy of the first AGI. Then ofc other companies including microsoft are more profit driven which explains the hope that they can initiate regulatory capture as all profit driven corporations are naturally incentivized to do","Tbh I try not to place intentions of individuals. Idk Sam Altman and I wouldn't be surprised if these executives were genuinely concerned about how AI could be misused.

It's just like, means, motive and opportunity ü§∑‚Äç‚ôÇÔ∏è. I could see it drastically limiting the efforts of FOSS AI communities."
1158836586407022603,"this is a fun/scary idea but the project would have to be relatively new given that AlexNet was 2012, transformers were 2017, and no one really took this stuff seriously until GPT3. I've not noticed any reports of notable AI scientists ""disappearing"" although I suppose some company could be a CIA front. But really I can't imagine the military brass being convinced to build AGI. Maybe this is my ~political~ bias coming into play but they'll throw money at promises of a bigger bomb and tell the nerds to bugger off once they have to try and comprehend the definition of the singularity","If they're to be likened to nuclear weapons, then there's probably some black budget Manhattan project already that we'll find out about in 30 years, or the next big war."
1158837087894765669,interesting i haven't looked into licenses at all. As much as I am an advocate of open source I've spent practically no time attempting to use them üòõ However I would like to say that to the extent that OpenAI is closed I will conflate that behavior with Microsoft. Might it be that MS is happy to open-source the stuff that's not making them money and keeping their competitive edge?,"I think MS is better than Meta. Lots of Meta's stuff is CC-BY-NC-SA, and I feel like the LLaMa 2 license gets way too much credit for being ""open"" (at least I'm not saying this in r/LocalLLaMa, so I don't have to brace for downvotes lol). To me, it feels like lawyers made it intentionally vague to set a precedent for future releases."
1158837319789465640,well but it's easy to do a good job on small advancements with no commercial utility. At that point it's just clout for attracting researchers to come work for them,Big companies are doing a good job tbh. Especially on smaller advancements which have less commercial utility.
1158838802761121812,oh fs I don't even want to think about the quantity and quality of data that the NSA has to train an LLM on. NSA-GPT would be so absurdly good at sexting terrorists it's not even funny,"Yeah I have 0 evidence for my statement ü§£ however I honestly wouldn't be surprised. The breadth and resources of the US military alone is mostly why I think it's possible. They've known about and been using AI for a while, and while I'm sure they'd utilize publically available papers, I'm sure they have quite a corpus of classified research and advancements to pull from as well.

Stuxnet comes to mind, and the NSA more generally, as an absolute goldmine of advanced 0-day exploits. I could certainly imagine a similar thing in the AI front."
1158840137589981236,"Oh fs I'd like to clarify that everybody's doing a very good job at sharing the math methodology used for architectures, but that doesn't defeat my point. The things that give these companies competitive advantage are hoarding H100s, proprietary data, and integration of AI with pre-existing products. If anything the game-theory incentivizes them to share the math behind architectures 1) it's not patentable in the US, 2) they want other research institutions to share architecture discoveries for their own use, 3) they want to impress potential employees to come work for them. 

To a certain extent yes it's great that they're all sharing the math, but I see that as a given in this field. I'll be impressed by their openness when Meta creates a facebook API or Alphabet creates a Youtube one to promote access all of their data for use in training your own models.","I disagree. DilatedAttention (LongNet) and RetNet are extremely promising (I really wish more people were playing with these), and DeepSpeed has been huge for training. DeepNorm looks like the best way to scale layers massively at the moment."
1158865119497961554,"Yes but i've heard it's not actually useable yet, very alpha at least a few months ago when I was looking into it",https://www.modular.com/mojo <- isn't mojo publically available now?
1167844193088061470,you‚Äôre prolly right but this sounds like a lot and i enjoy putting myself on watchlists so imma keep downloading stuff with safari,"# HOW TO USE ANNAS ARCHIVE PROPERLY : GUIDE NO ONE ASKED FOR PART 1
and i suggest people to use this with dark web most of the content here is pirated there are many harmful documents here like manuals to do stuff since they incorporate data from every source like banned projects like z lib as well (ZLIBRARY WAS A DARKNET MIRROR FOR BOOKS AND THE SISTER WEBSITE WAS TAKEN OVER BY FBI)  a year ago , so i came to know about annas archive , the best and easy way to use is this you download portable version of brave browser and then just  open a new window with tor and then use this website with the onion layer to anonymize yourself  , dont just go there from your main account specially there are some options that scan your browser and cookies so  please just make sure the tor network is connected and then search the book like you always wanted (YOU SICK PHYSCO) , then you can let them check stuff and its kinda okay not as dangerous as doing it without any caution"
1172089608868216833,"hmmm interesting question. I'd say the videos I'm going to care most about in terms of ""doing your hopework"" will be extremely rare and from the ""original research"" and ""THE BIG IDEA"" playlists. My most popular video category by far though is the paper breakdowns, and for those maybe just check out whichever have the most views or topics that catch your eye. If anyone has any interest in either collaborating on or stealing ideas from me, then the ""unvetted ideas"" playlist is where you should be looking.","Hey, I find you and your channel quite interesting I enjoy watching people who think deeply and let their mind be stretched out, because I know they will stumble onto what is true and beautiful.   I'm also have a software startup, so also in the field of AI and stuff.  So your channel is an intersection of multiple interests of mine. 

Have you any advice if I want to follow along but I can't watch every video?  I want to participate but I also don't wanna be ""the guy who didn't read the material"".  What should I do?"
1172090567832899604,"Would love to hear more about this in the future, feel free to let us know when products release (as long as it's still giving off small server casual sharing vibes rather than straight advertising :P). And if you're looking for employees this discord might be a good place to find them; many people here seem to be either working in the field or currently at uni. I got my current gig at LearnPrompting.org through them approaching me after finding my channel, and I'm always open to opportunities","Hey thanks for asking. In short, over the past many years I've built some pretty good tech (full software abstraction) on top of which I am now ready to build and sell a bunch of software products.  Gonna be doing that for the next decade.    

There are some specific projects in the pipeline.  Some I've been dreaming to build for years, some are recent ideas.  Some are small, some are big.  They will all get done.

The one most connected to this discord is ""AI Discovery Labs"" .... A cross platform client application for multiple AI models who can work together.  (Lots of people are doing that, though I have some awesome differentiators.)  ....I also want to use it to perform experiments with AI.  If you have any questions, ask away."
1176269772338511925,holy crap we're at 700 now???,https://www.nytimes.com/2023/11/20/business/openai-staff-exodus-turmoil.html
1176343149359145110,good point thanks patrick i'll figure out a better time for them tomorrow,"Great idea to start a livestreaming!
8pm in NYC = 1am in Paris and before 7am in all EU countries.
So EU people will be probably not connected at this period of time.
About the OpenAI staff crisis topic, I didn't have interesting opinion or information to share.
About GPT-4: in fact, many OpenAI models run on Microsoft cloud, so GPT-4 could probably  continue to work as usual.
About GPT-5 project: if OpenAI just use GPT-4 to add more abstraction in his corpus and datasets (using a kind of Chain of Abstraction) and a brute force massive training, it could  probably gives better results without any new disruptive innovations.
All my best wishes for the first livestreaming!"
1176359648585064468,"hahaha great message but don't worry about me, if anything i'm a bit too good at living in the moment and not working enough","Happy bday, bro. Just read on reddit some posts about peoples regret in their 20s and most of them are saying, working too hard, or doing almost nothing in case of private life. Just remember even though we all have some aims for the future even though it is our passion this whole ai thing, dont forget to live life"
1176677742071251084,might it be when i pinged everyone over in #deleted-channel ?,"@Tunadorable hey, you pinged me for a response recently and I opened it, something else came up, and when I went back to look for it I couldn't work out where it was. But I know it was important."
1176683301419888681,oh then i think it's in #philosophy,"Nah it was a direct reply, and lengthy, but yeah, not sure"
1176700029226979509,smooth recovery there yes let's try not to resort to insults,This is my autistic interpretation of your words.
1176915112074936510,ok that sounds cool,"Yeah there definitely is. No no no, you misunderstand the story as being directly indicative of like my intentions here or something. Right, so if you wanted to, you could make it so words that sound similar mean similar. Or you could give each word 14 meanings corresponding to each of the 14 quantum operations, so each extra word you say multiplies the complexity of the statement"
1176916307766165564,no crown thank you i'd like to eventually get this thing to a place where i'm not even in charge anymore,"Also, if you want a crown, get rid of the admin permission on your role"
1177112738707800085,basically what we're talking about over in #general,Yeah and i summary of the last conversation or smth. If no one is doing it i could help with that
1181686385233637418,that and an office365 subscription is already wayyyyy more expensive than $20 per month. their margins are already so high on that dogshit software suite that they can prolly eat the crazy increase in costs from running GPT4 so often,"Of course I'm sure this is because they plan to use the data for more training, advertising, etc."
1181687666010497035,"i think you underestimate the value of proprietary data. in every other tech field companies rely on a variety of factors to stay ahead of their competition (pre-existing market share, brand, beating others to market for a given feature, etc) but patents and the exclusive right they give to use certain inventions has always been a big one. when it comes to AI that government-enforced exclusivity is (mostly) not available. However, proprietary data, especially a lot of it that's very high quality, can drastically change the performance of a model (look at chinchilla or that 1b parameter code one from the ""textbooks are all you need"" paper). No company is gonna have as much high quality business data as microsoft to begin with, much less after this. google is a distant second and then after that it's a ghost town. I imagine microsoft's data eventually allowing them to be first to market on key AI services like ""completely automate away your middle-management, powerpoint monkeys, and really any remote worker in a manner that is personalized to your own company's knowledge-base""",data for more training >>> seems unlikely to me tbh
1182020546326708306,hahahahha i was thinking this ~10 months ago and decided it'd be easier to just quit,True. I really wanna automate my own job before google does it for me.
1182028807440437349,they should use the excuse that they're already using gemini to replace their front end devs,Some frontend dev is in shambles rn
1182042298704465970,yes but i don't have a windows pc or an office365 subscription and bing search is useless given how insistent it is on searching instead of just answering,openAI boutta make gpt4 free >>microoft plans to give out chat gpt 4 for free anyways
1182042415813640245,"""pro"" makes me think the biggest model will have a $ charge alongside but i haven't heard anything about this",so gemini pro should be on par with gpt 4
1182042956119683164,wait but these make me think that gemini pro will be behind gpt4 and gemini ultra will be on-par / slightly better,Found these on twitter
1182044675264217160,catch me cursing out siri until the day i die,when i get my pixel 9 and i can say breain dead things and it gets transcribed to text offline
1182044832940703826,üò≠ when he implicitly insults my coding abilities,its really good at python tho
1182045061312168037,you keep saying this and i do not understand it. it's all just chat interface with different colors,i haate teh whole chat gpt and copilot interface
1182045104702226483,ok for this totally i'm loving how open interpreter is progressing,i want ai that acts liek debugger for me
1182051201504788560,"a model architecture. relates to the hypersphere video i posted awhile ago (btw if anyone's curious, hypersphere norm has already been invented, it's called cosine normalization) but also the paper ""Think before you speak: training language models with pause tokens""",@Tunadorable what are u currently working on the most
1182053339555450880,i'm not including all of those bc it sounds complicated but you've tempted me into having ChatGPT code up an example population. i may or may not have some pretty graphs and simple equations for you to look at in a few minutes,^^
1183969267109089421,way better reason than what I had thought up,"I totally agree, especially if we want to integrate some Bots here, who may be summerize the State of the Server in certain topics, it would be beneficial if the Natural Language is clean"
1184311418670043146,"i know the default on OpenAI's playground is ""you are"" and that's also what was used when bing search's sydney prompt leaked months ago. haven't seen any actual measurement of this though. I'd avoid ""I am"" because it's highly likely that the user will be speaking in first person","for system prompts does anyone know whether saying ""You are"" vs ""Assistant is"" vs ""I am"" is better?"
1185160266594402414,It‚Äôs just all swear words. Auto mod doesn‚Äôt exactly have the intelligence of a GPT model for checking whether a message is actually toxic or not so preventing swear words is the only realistic approach,i dont know what words are being blocked here
1185160783206830151,"Haha just use the OpenAI playground, I think it has all of those. This is the big brain way to use ChatGPT 

https://platform.openai.com/playground","im no frontend engineer but i want a chatgpt interface where you can make the text window wider, edit assistant messages, edit your messages while keeping the messages after them, edit system prompt including mid conversation, etc."
1185181515995422720,"i'd bet whatever is the norm for markdown will do best, and then latex second just bc of training frequency","Like is this
```
Brief primer for my task. Here is context:

""""""
Does this kind of technique matter at all?
etc.
""""""

Full description of my task. [optional ""extra addition"" e.g. ""let's use our numerical command and clear thinking to quickly and accurately decipher the answer"" or whatever]```
any better than this
```
Same context as before
Full description of my task.```
and by how much, and does it differ between models?
Should we use """""" or --- or something else? What is the most effective? Does this differ between models?"
1156987565325418517,oh they‚Äôre they‚Äôre tunadorks fsfs. make me look like an absolute Thad,are they all nerds ??
1158974051742646272,ah amazing point except i‚Äôm a wackjob that doesn‚Äôt care in the slightest about interpretability üíÄ happy to have you so hype to discuss this,Since (as I understand it) their embedding spaces aren't very coherent/interpretable.
1169907344130461776,"nice! happy to have you! Not sure i'm really qualified to give advice on applied math in general. all that really comes to mind is to repeat back what this guy [paul christiano](https://www.youtube.com/watch?v=9AAhTLa0dT0&list=WL&index=23&t=15s) said to me a few mons ago which is that if you want to get into AI there's no need to get a degree, just self-teach if you think that's something you're capable of / interested in. Academia just can't pump out researchers or AI engineers at the speed that industry demands them rn so they'll hire anyone with a cs/math background","my cousin is a topology phd im trying to get him into ai. im a bioinformatics master student, neuroscience background. similar autodidactic curiosity with AI for awhile now. Cognitive science junkie. Dieselpunk. Considering phd in applied math as all my interests gravitate toward only a handful of mathematical subdomains. any advice would be appreciated on that front-- cheers hope to learn from yall"
1171559686147940352,haha bet I just created  #ai-economics. I'm gonna say that channel should be usually for discussing stuff like jobb losses & UBI but this server is still plenty small enough to be loose with our categories so feel free to talk about econnics generally,Ai and Econ are my hobbies! Where would be a good place to talk economics without derailing threads?
1171559749880381592,I will warn you tho I've got some spicy economics takes,Ai and Econ are my hobbies! Where would be a good place to talk economics without derailing threads?
1171578996975214612,"So I was talking to this guy Paul Christiano (inventor of RLHF & former head of alignment at OpenAI) and he confirmed for me that it's totally legitimate to just skip formal education. If you feel like you learn better in a structured setting then go for it, but if you think you can self-teach then you will get hired off that because the industry is demanding more smart people than academia can produce.  That's what I'm doing rn and I think it's going pretty well, although to be fair I do have an undergrad degree in math so might not be a fair comparison

Also I'm always looking for help on projects üôÇ","Hey everyone!
- I'm a first year college student, been interested in AI for the better part of a decade (Picked up javascript when I was around 8 years old, been fascinated with AI ever since I found out it existed) and want to get into AI research. Although I worry about how fast the field is moving vs. how slow it is to get degrees.
- I spend a lot of my time working on cool projects that are often way too big and don't go anywhere, watching 3b1b style math videos, and watching AI videos. (Because of one of those projects I have a pretty cool dataset of game state and inputs from hundreds of thousands of matches in an online game, which is actually pretty cool since as far as I know it's a fairly unique dataset. Only thing I've used it for so far, though, is creating a leaderboard of players since the game doesn't have an official one.)
- I have a lot of ideas that I wish I could try out but more often than not I never get the chance.
- In an attempt to get experience that will help me get an AI research position sometime down the line I am currently doing some work making a chatbot that can retrieve data from an API to answer questions. Although it's been very difficult to do that and as many classes as I'm taking right now, since the opportunity only presented itself after semester started.
- If anyone has any cool projects that I can be involved in, that would be super awesome, if I can help out at all! That is even despite my super high workload that I'm stuck with for the time being."
1172087926813900822,since you're curious,"hey guys where's everyone from, I'm in australia"
1179147645135093800,how did u know i once did the carnivore diet for 9mo. i am insufferable,https://youtu.be/AaHbfrryeYA?si=xt-3nNIXz0F5E3RD
1179154332206239795,"it essentially functioned as an elimination diet. cured gut problems I had been to multiple doctors for, and that cure has lasted for years after abandoning the diet. other side effects included 
- making it ABSURDLY easy to fast for days
- having relatively constant energy levels throughout the day (no afternoon yawning or need for a nap)
- falling asleep immediatelu when my head hit the pillow. this one has mostly lasted past the end of the diet. beforehand I was a borderline insomniac and now a difficult night sleep is uncommon
- debatably clearer skin (this was in high school)
- debatably lower libido (i didn't strictly measure but that was a vibe i got)
- an aversion to all forms of carbohydrates in terms of what my tastebuds found interesting and getting headaches which lasted weeks after leaving the diet
- weirding people out

my daily meal was 3lbs of 70% lean thick half-pound medium rare burgers. would've preferred to do ribeyes but i'm not made of money",How did it work for you? I've heard mixed reviews. Might try keto at some point. Carnivore doesn't seem practical for me ü§î
1179155183444430888,"nope. cholesterol stayed fine, both levels of ldl & hdl as well as the ratio of the two. the levels did go up a bit but still within healthy range. of the two doctors who saw me (i transitioned from pediatrician to regular physician during this time)
- the first was all panicky when i told her but then none of the lab results came back the way she predicted so she mostly shut up. the exception was one blood test i got where i was low in vitamins C,A,K & E but turns out that was just because i had been fasting for like 3 days before taking that test which is way too long. got another a few weeks later and they were all fine
- i chose the second doctor because she was a family friend and already had a patient on the diet who she called her healthiest patient",Did your cholesterol skyrocket?
1179155587578220647,"i mostly stuck to this for about 3 years afterwards. much more reasonable in terms of people not thinking i'm insane, and i did feel better than SAD but still not quite as good as carnivore. couple pounds of meat and a week's worth of salad per day will do wonders for most people",Keto with only meat and vegetables is probably better imo
1179155901739970630,"for 3 months of it (summer vacation before senior year) I would get up, run on avg 10 miles, lift for ~1.5hrs, then do an 8-12 hour shift waiting tables 6 days per week. some days I didn't have time to eat so i just wouldn't. felt like an absolute animal",I think it had a mildly positive mental effect and mildly positive athletic performance effect (I was doing a ton of running at the time)
1179161581599334511,"yeah as a temporary elimination diet I think it's amazing. while it's definitely *reasonably* healthy to live off of for an entire lifetime if you incorporate organ meats for vitamin diversity (see the Inuit), we really just don't know enough about the Dr Shawn Baker ""only ribeyes"" approach, and we won't until those people reach their 60s-90s. I also think people underestimate the extent to which individual differences (genes, gut microbiome, allergies, local food quality/availability) effect what will be best for you, like for example some people are straight up allergic to red meat. My prediction is that we'll find the keto/omnivore/Mediterranean diet people living longest, carnivores in second, and everybody else after that

if/when you try it lmk and i'd be happy to give specific advice and more details on what to expect","That's awesome. The main benefit I've heard from people is that it functions more as an elimination diet, and I think it does a good job at that. It's kinda the perfect elimination diet because you really only eat one thing and fortunately it provides all the nutrition you need. I think that often times people inflate the benefits of carnivore with the downsides of our normal diets. Most people feel relief but it's less due to the new diet and more due to the abandonment of the old one. Maybe I'll try carnivore at some point ü§î"
1179167629492105316,"i can't lie the first 6 weeks of carnivore were not fun in the bathroom. If i hadn't been going into it with pre-existing gut issues I probably wouldn't have stuck with it (my previous issues were worse than what came up on carnivore). It really sucks but i think in order to properly understand how any diet effects your body you need to give it at least 3 months, which is ofc totally unrealistic and sounds like people who say ""oh i promise the show picks up in the fourth season"" but it's true. takes awhile for your body to flush bad stuff out, adjust to a new energy source, etc",That's a good point. For a while I thought I might be interested in trying carnivore for a month. I can see that thinking as being useful for experimentation but if you want real results you have to think in terms of a lifetime.
1182019988782055474,i'll check em out,Kunzite and The Symposium both go hard btw.
1182209484358160414,C418 easy,Favorite minecraft song (better than personality test tbh)?
1187276723067306095,hahaha i can't lie i still go back & look at the first one sometimes,Bilal know that his memes are trash << i posted one meme here that i made myself and i m stil very delulu about that
1187560158340067469,not the knights of the old republic videos giving me flashbacks üò≠,"holy youtube channel link , time to go down the rabbit hole ig"
1187878640780840971,"trouble with generic content is there's some kind of tradeoff between the spectrums from generic to original and low to high quality videos and then looking at hours invested per video and success per video. if my goal were to get big on youtube then fs high quality generic videos would be the way to go, but my goal is to do actual research and this yt thing is just a networking/resume side project. therefore the low quality high originaly videos i feel work better",i think @Tunadorable  you should start makng more generic content on youtube that would be better in the long run
1188592475221262376,yooo i hadn't thought of that. might start sending out emails that'd be hype,Thanks for the shoutout in the video! That paper definitely fits in with what I was talking about a while back. Have you considered doing any interviews with authors of papers?
1188654820475809863,interesting i could see that,"On an unrelated note, I saw you bring up Stockholm syndrome in a video. I‚Äôm pretty sure it‚Äôs a scam invented to victim blame and discredit hostages in a botched hostage negotiation."
1191876867301572608,As a fan of many types of metal but specifically psychedelic alt metal i take offense to this,BASED
1157342508532125706,"Yes from what I've seen that's pretty common for small test models. Maybe only code or only a simple algorithmic operation like modulus addition. But when I looked it up it seemed like GPT-2 can be trained for a bit over $100 of cloud time on an A100 nowadays, need to confirm that","Train transformer with a full corpus in English could be very heavy with 1 token=0.7 word.
To test a new transformer architecture in an iterative way, it could be interesting to consider a sub part of the language and/or smaller tokens (characters, bit, etc.) has a first step to validate new concept with smaller training time/cost"
1157344678270750751,"I'm just not so sure about phrases in terms of ability to generalize. If there are x number of words in the human language then for 5 word phrases that's what x^5 possible phrase combinations? I know we're only using the most popular phrases but still, intuitively I'd prefer a model that thinks at either the character or word level. That's the motivation behind my encoder-decoder^3, no need for phrases but we still get to do aggregated comprehension & planning","Yes, but with phrases, 1 token = as many as 15? words (I think that's how far ""Copy Is All You Need"" goes, but it still spits out subword tokens)."
1157351546967818250,I think the big problem though is continual forgetting. And it's harder to vet the quality of newer data which makes continual forgetting worse,"Like, just giving a model retrieval capabilities and punishing it for stagnation seems like it could go a long way."
1157351609148395631,ah that makes sense,"And switching again to phrases: [Copy Is All You Need](https://arxiv.org/abs/2307.06962) basically did what token embeddings already do with subword, taking the most repeated phrases (at varying lengths) in given datasets and adding them to the FAISS index. Similar to just giving token embeddings a huge (e.g. 1m) vocab size (the larger TokenMonster models, for example, have phrases in the vocab after they ran out of sub- and single words in the corpus). The paper's model falls back to subword tokens if it decides a phrase isn't appropriate at a given point. So new phrases could still be represented by subwords until they reach critical mass and then get added to the vocab."
1169229897781235742,"ok i'm loving this idea. So the whole issue with continual learning causing catastrophic forgetting is that the new/live dataset has a different distribution from the pre-training dataset. Training a separate classifer model or something to deliniate between [new data that is similar in distribution to pre-training] and [new data that is different in distribution to pre-training] would allow you to mess with the ratio of the two, and further decide how often you want to re-use old pre-training data. big if true","About Continual Learning, I thought that human have functions:
- to detect what is opposite to the basic law of probabilities (equi-probability is not respected or missing)
- to evaluate what is new or unusual (out of the clouds of the pre-existing distributions)
- to modulate there training when something is unpredictable or less predictable
So, perhaps it's possible to modulate the learning process to avoid catastrophic forgetting and over-fitting in neural networks using reward and penalty"
1169711532486172755,"language may be largely localized in the left hemisphere of your brain, but thinking certainly is not, and can in fact be split up into individual ""people"" by surgery under the right conditions
https://www.youtube.com/watch?v=wfYbgdo8e-8","About Mixture of Expert: 
- MoE is analog to a human team
- LLM is analog to a member of this team
- Human brain is not a team of LLM (language area is a kind of deep unify network)
So, perhaps if a LLM do not capture a part of the knowledge from a training corpus like human. (cf. example in the study*), then the LLM team (MoE) is limited and is not analog to a Mixture of Human Expert (MoHE)
* 31/10/23 paper: https://arxiv.org/abs/2310.20384 at this time"
1183551919931793458,"seriously excited to getting around at looking into this, but i have a feeling i won't until it gets incorporated into some serious open-source models","The sweet thing about this one (if it scales) is that the ""attention block"" and the ""MLP block"" are the same block (hence the e.g. 48 or 64 layers in Mamba vs 24 or 32 in the Pythia model of the same-ish size, because Mamba doesn't need a separate MHA and MLP block for each layer)."
1188563853328527381,"i think for SoTA stuff given that we'll be transitioning to new architectures/methods all the time we'll always need to stay closer to the generalized processing side for that. but once we have models which are ""good enough"" for a given set of tasks we know we're going to want to do a lot of, then yeah over time we'll create specialized hardware, kernels, software etc to run those models. but it will be a nightmare managing it all. like look at apple M series chips rn, they've got CPU, GPU, and ML engine, which you can only use in pytorch if you jump through separate hoops to get metal running. Imagine if eventually they also build in part of the chip that's specifically for transformers, and another that's specifically for diffusion models, etc. Going to be quite a lot to manage

not sure where i heard it but i remember months ago some youtube video mentioned dynamic hardware, meaning processors that could reconfigure themselves between CPU's and more specialized processing units on-demand","Yeah I'm not gonna pretend it's credible or promising or anything but AI Explained mentioned it in a video, it intrigued me, and I figured other people here might be interested in knowing about it. Hyper-specific chipsets may be the future of hardware engineering."
1190191600517783562,"My impression is that as long as a model is more good than it is bad then synthetic data does the opposite. Raw data has some % of examples that are biased (for example racial bias) and whether you're using regular data or synthetic data, you distill it by filtering out biases (ask the model to label all data examples as biased or unbiased. include the unbiased ones in your next pretraining dataset). Do this iteratively and the % of data points in the set that are biased drops each time. To be fair I'm not sure if this generalizes from bias to creativity, it may not","Well I'd be easily convinced that current models could create truly novel data, however my biggest concern is that synthetically generated data would magnify any inherent biases caused by the previous models. Consistent mistakes and hallucinations from before suddenly become much more pronounced as the mistakes in the initial training set grow into the new one. Not sure if there's a way around using synthetic data though."
1191764533782519950,not me but i've been thinking about something like this. not sure why yet but my intuition says we're going to eventually have to find a way to combine traditional embeddings & graphs in order to get really efficient use of said graphs. don't know enough about GNN's to really say anything though,anyone ever heard of this or anything like it? I had this idea a while ago but lacked the time or resources to develop it: https://snap.stanford.edu/class/cs224w-2019/project/26418192.pdf
1156635135379247144,Yeah I like him. Timely high quality in-depth stuff,What do you think of Wes Roth? I've liked his stuff so far
1160220334792912947,yes my point was that i tried to make the code-llama 7b 4-bit do something like this in open interpreter and it‚Äôs just so absurdly far from being useful. if that 3b one you mentioned is better then i‚Äôm fs interested,you can make these do so much sky is the limit imagine if you program these to go into your file system and take the names of the arxiv ``234.3234`` papers folder and it can read the titles and automatically title the files and then generate short titles for each file and then a python script takes over and then rename all those files or you can do little things that it would be stupid to pay open ai api for
1164988527419867218,very relatable,"That's right. I forgot all about that video. I've thought about a paper maybe someday, but any of my ideas are stacking so many others that it would just be a gangbang of citations and ablations."
1171262617780768829,128k character context window?!?!?!ü§§,What do you guys think of the new openai stuff?
1171363205092749352,"Claude's 100k came out awhile ago now & there have been quite a few papers attempting to fix this issue in the past few months, including some which were drop-in replacements meaning there's no need to re-train a model from scratch, so fingers crossedü§û but i agree it's unlikely",We've seen the accuracy at the center dip further and further with increasing context window
1172591529215393953,@Invertedsimulation feels disrespected lmao,@‚Äãeveryone  i want to present an IDEA here and i want you guys in your free time to give it a read  specially people like @Patrick Lanquetin  @Tunadorable  @QuantumCat  your inputs will be well apprecaited
1172598084442792006,"the different trimmed down correct knowledge graph we provide it post-training, not the huge corpus of text created by our initial internet knowledge graph fuckery. The post-training one we provide it would really be its only option unless we give it the ability to surf the web, in which case it'd be so logical as to likely be able to successfully create a similarly good knowledge graph. The thing i'm trying to do here is 1) massively expand our training data in hopes that this will bring about AGI and 2) make the AI skeptical of its own memory and instead choose to rely on outside sources, thereby mitigating hallucination which I see as a serios threat for misaligned AGI",Why would it trust your knowledge graph? Wouldn‚Äôt it have learned to be skeptical?
1173104189191233566,you bring up a good point but you're wrong. I will be the one to create artificial conscious super intelligence. sorry not sorry üòõ,"üòÜ  that's a very serious charge! I can respond with my thoughts since you've been asking though. I'm not an AI researcher but just got done with a period of physics research.

The Bitter Lesson comes to mind: http://www.incompleteideas.net/IncIdeas/BitterLesson.html 
The bitter lesson is that AI breakthroughs have been won by general methods trained on absurd amounts of data with a ton of computing power. So progress in large AIs seems to be to use general methods and then go back later and study what the model is doing (interpretability research). This seems really stark in everything I've studied with NLP and procedural generation of text; decades of really clever research and text and programming language systems, and the results always struck me as really janky and stuck at ~1990's text games level of quality! So when you say ""look at a piece of information and link it to its knowledge graph,"" I worry that this would be equivalent to putting in specific mechanisms by hand, which oftentimes just doesn't work!

Also, we have to worry about training complexity. It's fine if you design a model with just the right knowledge graph representation, short-term memory, long-term memory, working state, access to tools, etc. and it would be AGI if only you could find the right point in 9 billion dimensional space! But if it doesn't scale with the # of GPUs and we can't do backprop on it, then we're still dead in the water.

But I hesitated typing all of this because my interest is really in applying other people's models! Right, I think it's a safe bet that none of us in this server are going to train an AGI base model. But what we can do is be on the forefront of applications, fine-tuning, and explore capabilities of models that researchers missed! So that's the stuff that's really exciting to me and that I want to argue about / create in this server üôÇ"
1182087837592596521,"one of the papers i was considering writing for a bit was on how proprietary data is the new alternative to patents, except patents eventually run out whereas companies are allowed to keep proprietary data to themselves forever. messes up the market quite a bit by *potentially* creating permanent monopolies in industries where startups have absolutely no way of getting data until they're already in the business",Probably a big demotivator for startups
1185063685056630825,"this is the real question, can you beat them to it. i think it depends on many factors relating to the the specifics of your job and how committed you are to it

i was debating this at my old economics research role. the things in my favor were
- boomer boss would be the last person to jump on AI tools, so my proposals had a time advantage
- because of confidentiality we couldn't upload any of our data to the cloud *in theory* but in reality we broke rules to use cloud storage systems constantly
- it'd be pretty easy to automate in the sense that some python generation & a couple GPT3.5 fine-tunes would cover 50% of the tasks

and against me were
- even with protections like confidentiality, we'd just get out-competed by a company that embraces AI sooner and losing a job is no better than getting automated
- because of confidentiality we had to delete our own work after a case was finished, meaning there wasn't much to train on
- it'd be pretty easy to automate in the sense that GPT5 prolly wouldn't even need fine-tuning

eventually i figured i'd rather change fields than race with megacorps just to keep a job i hated",I'm hoping I can automate myself out of my job before Google can ü§î
1185069974096715826,very interesting point,"It's also worth noting that the Mega Corps that would be making these tools are full of people who's jobs would be directly automated if they were successful. I have doubts that the software engineers at Google are just gonna go ""yeah ok we'll automate our jobs no problem how could this go wrong?"", at least without _some_ form of resistance. This gives me faith in the open-source community"
1185070100731138129,the self-promotion thing is more for spammers jumping on here. i'm fine with y'all legitimately sharing ideas & projects of yours. I'll clarify that rule,"Agreed. I definitely don't want to compete with Megacorps, but I think that my main advantage is that the Mega Corps are competing on an extremely generic enterprise level. This is fine, but this means that there's plenty of innovation to happen in the niches. I mean think about it this way, you don't just hire the most generic software engineer you can find, you want the most capable for the specific job. So I figure on one level, playing to that niche idea is going to be useful.

On top of that, there are already a large amount of tools available in the open source world which have the goal of being an AI developer, just none of them work very well. I've decided to prioritize theorization and planning in my strategy in order to make sure that I have a strong foundation when I actually build the thing. The main things that I think people have gotten wrong so far are:

1. Focusing on tasks rather than orientation: the agent needs to be able to orient itself in the world, which requires a strong sense of its environment. Task execution is fine, but I don't think that the perception given to the agents is good enough yet
2. Not doing developer tasks the way that developers do tasks: I want to build a system like a Text-Based IDE which allows an AI developer to perform tasks in a similar way to how human developers operate
3. Focus on memory retrieval rather than memory creation and experience gain: one thing that I think is really important for a developer to do is mold themselves to a codebase, which takes shape as gaining experience. Just vectorizing a codebase and performing fancy content retrieval for the AI isn't enough to make it experienced IMO, although I'm not entirely sure how to solve this problem yet

Those are some initial thoughts, and if you're for some reason interested in hearing me talk more about this, I did make a [video](https://youtu.be/JA8MsCqAdJ0) about my plan (I hope that doesn't count as self-promotion, will happily delete if so)."
1185156952796442644,"‚Äúthe best they can do (the way they are built) is to suggest something they have already seen‚Äù
- yes and no. if a given task has grokked then the model does actually have a low dimensional internal representation which generalizes to unseen scenarios, but I would agree for a large % of code this has not happened yet
‚ÄúForgetting the meta step of actually coming up with structure to write good code‚Äù
- great point. Getting models to plan rather than be simple next token predictors is a huge problem to be figured out that Ilya seems to have recently come to the decision that he can just ignore. Architecture I‚Äôm working on rn hopes to fix this
- hmmmmmm I‚Äôm no programmer but when you‚Äôre coding is it realistic for you to write your own tests before you‚Äôve written he codebase? Again never written a test in my life but I‚Äôd imagine it‚Äôd be hard to do if you haven‚Äôt already solved all the unknown unknown problems that you stumble upon while writing the meat of the code. If I‚Äôm right then writing tests first would box you in. What you‚Äôre saying does make more intuitive sense for me in the case of vision tho.","*I would like to add to this idea a little 
## Problems i see with the current agent based systems 
- They are not agents  , in the true meaning of the word agent , you are relying on a token prediction system to reason through software enginnering practices , and all the information it has is the code it already has seen on github so the best they can do (the way they are built ) is to suggest something they have already seen 
- Focusing on wrong things : 
most of these agents are being trained to write the code , forgetting the meta step of actually comming up with structure to write good code in the first place , which is most of the software engineering in the first place , i am very noob at programming so for a person like me i need to stop and think about how to strucutre  my code so its easy to refactor later 
- having no clear goal to optimize for : 
if you are building an agent to code what is your reward function for that 
, some one else needs to check the code base to see what the ai made , and these prompting techniques are a big gamble so how do you make sure that *Agent* is doing what you want it to do 
well an idea is test driven devleopment 
# SOLUTION???
it creates the tests , and then writes the code 
if its a UI  , it takes  a screenshot of the project send the image back to the AI model **VISION** model and then takes critique from UX Designer **expert** to reiterate on the code 

so many different useful AI models can work togather to do this tasks 
or iamgine if we can finetune **MISTRAL 8*7b ** to be like exports in all softwae enginnering fields , like each expert , the first one is requirement enginner , srs documentation creator , second one creates the UML diagrams and use that as axioms to 1. write tests , 2. validate after a state is done by the use of tests , then Coding assistant comes in and codes and it code s untill all test pass , vision model checks the UI , QA agent checks the code conventions"
1155956014378668042,I've been showing it to all my friends and family they're so confused they keep assuming I'm the virgin youtuber üíÄ,@danichka @Tunadorable idk i am weirdly proud of that meme
1166456774363189338,"https://youtu.be/4KQhGY51i8o
paper being discussed in this video is linked in description. basically tells you how to manually turn a tensor into a hologram. personally I think that superposition of features in a model is effectively a similar computation to what's being talked about here","@Tunadorable Do you have any resources on holograms? I think there's a possibility of the model encoding some holographic-type algorithm that I could do mechanistic interpretability to detect. When you get good enough at prompting language models will start saying things like ""text is a hologram"""
1166457236785209376,yo could you send a link to this chatGPT conversation?üëÄ,"@Tunadorable Do you have any resources on holograms? I think there's a possibility of the model encoding some holographic-type algorithm that I could do mechanistic interpretability to detect. When you get good enough at prompting language models will start saying things like ""text is a hologram"""
1179501631633633351,"I already disagree. asymptotically approaching ""talks like"" is the same as reasoning with some % error in your reasoning. As far as i can tell LLMs can do some level of reasoning and it sounds like with Q* they've really figured out reasoning, which is essentially just an exponential search problem",first of all LLMS will be able to talk like master degree or even phd level people but will never get to the reasoning level of any one close to that
1179503023253372928,"i could just take the vocabulary size and map out all possible token sequences. then boom, i've got an exponential search problem just like the one alphaGO solves. only difference is that the exponential space of possible sentences is far larger than that of white & black circles on a 64x64 board, which means it'll take longer for our exponential search algorithms to get that good","alphago's >. they are not creative on language  so the thing with them is they are trained on very very large amounts of go games but nothing in the language can map to somethingn like that you are talking about the detereministic game of go tha t has a end point to human intutiveness and language , the way they trained alphago was they gamified the traning loop and gave it alot of examples"
1179503282595561583,we can make these deep learning algorithms without understanding them at a mechanistic interpretability level. to suggest that we need to understand something at that level in order to create it or to create a better version of it is clearly counter to the past 10 years in the field of deep learning,"there is no magic sauce to our brain that allows for understanding or creativity. >> oh i very very  much respectfully disgree on that 
if there was a way for humans to understand the brain fully they would ahve made a better brain"
1179512754881708063,"good distinction you made here between your potential ability assist someone else and your abillity to explore your own ideas. i still think my point stands if we're talking about just a collection of undergraduate degrees

however then you talk about having multiple undergraduate degrees to compliment a PhD. this is an entirely different conversation. I totally agree if we assume that GPT does NOT turn into full on ASI and creativity is still left to humans then yes any PhD would love to have a bachelors of knowledge in a different area to augment their creative process. Having just a PhD in economics and then asking said non-creative AI ""help me incorporate ideas from other domains to work into my subject area"" certainly would not go well given that GPTs are next-token-predictors meaning they will tell you ~average~ thoughts and average thoughts are by definition not creative. 

So i guess you could say after some hammering out of exactly what we're talking about here then we're in agreement GIVEN THE ASSUMPTION THAT GPT-N WILL NEVER GAIN CREATIVITY","Why would a PhD work with you, someone with ~5-12 undergraduate degrees, when they could work with GPT5/Q* which effectively has a masters degree in every single subject

> So this is a valid argument and i would not work with some one with half baked knowldge of something when i have chat gpt 5  or anything like that , **BUT** i am talking about that in terms of your personal knowledge  , you yourself can confirm this that knowing maths , philosphy  , computer science basic , and ai and stats all these things give you a  super power and you are using that super power to talk to me right now  m , you are thinking in terms of mathematical models to reason about genralization of knowledge and utility of learning  
> 
**lets say you are at this interview and the person says well we would not want you as a new hire for this postion acutally we have chat gpt 6 that knows maths and sats and also knows about ai can do mlild reasoning as well can read papers as well and can think about it as well**

you would go wtf thats some bs you are talking about right , any level of llms with any form of Q* will never in our lifetimes beat a human who is specliazed in a domaini like a phd and even has a bachelors levels of understanding of  other domains 
and Q*is not some msg to fried rice that can change your entire world its just policy  based choosing game at its core and will always remain as such that people will know from atleast a decade but you wonder why Q* never got us to agi right , Becasue it cant and it never will"
1179722657340596295,"ok cool if your objection is one of difficulty/scale rather than of categorical possibility then I can understand that. I'm not completely convinced though. i'd like to revisit the scaling laws paper and compare the current trajectory of the loss function from GPT1(j?) to GPT4 versus the perplexity of true human text. That should give an estimate as to which GPTN will reach creativity if we assume that GPTs can even do so. However, I do also see it as quite reasonable that maybe the scaling laws will start to break down and GPTs will only be able to asymptotically approach the best human text. In theory that would be where an exponential search algorithm like the alpha models come in, although to your point we don't know how far off we are from said algorithm because we don't know the intrinsic dimensionality of human cognition (in comparison to folding proteins)","so when you say that the problem is computable , i agree yes it is but its orders of magnitude more harder then any thing humanity has ever solved 
and i have same intuition about intellgence as well it can be a computable problem with some crazy insane computational complexity but 
i think people undermind that how hard is it to get the neuro linguistic patterns right in such a way that will produce creative results ,

### Think of it this way 
if lets say your theory is right can we train a smaller model that is just capable to make human like sentences from scratch , no next word prediction or simple reward fucntion , so i have been very curious with how human brains work and i sometimes look at scans they do when human brain is thinking something and even if you think something billions of neurons activate and many many parts of your brain are used  see teh atatchced image of the human brain fucntion i had sitting on my hardrive and these are not too accurate but very close predictions , so everything you are thinking you are using so so much of your brain without yout knowing and getting over whemlmed that humans now just take it for granted that when we learn a word how the part in our brain reason through it and then all these parts of brain activate to make sense of it and we are doing it for millions of times maybe billions in a second and decoding languge is trillions of times more computationally complex then any match of GO  or chess or if we play all the board games in the world combined 

if we deploy your search technique to alphago or any branch prediction language will keep on going where is chess or go we get a finite number of moves , so you can think about human thinking as alpha fold and our current ""smart llms"" as abacus"
1179722785581449226,"I wouldn't say ""in a snap"" but essentially yes I do think that we'll get there as we scale","i agree with anyone who says that intellgence like systems can be created , but anyone who says if we expand the search or we expand the gpus use  like a trillion gpus use all the silicon on earth we will in a snap crack the code to  intellgence  , i think this wont happen"
1179723766486548600,idk man i feel like i've been hearing a lot lately about analysis of different problems showing surprisingly low dimensionality and when i look at something as difficult as inventing a GO strategy that's not only novel but also good enough to beat the human champion I don't see how that's different (whether it be categorically or in degree) from creativity in the arts,"and my previous chats and interactions with people here may give the impression that i hate open ai and chat gpt 4 and i dont beleive in Q* and this is just not true  , i find these llms very very useful (although i beleive they dont even poseessss the intellgence of worm ) let alone a bird humans are too far just too too far , 

i spend a lot of my time in creative indrustry , design , 3d product sector , film nd i wont sing my parises but there are people i have worked with who can do stuff that  i have a very film beleive in no ai will be able to do in our lifes , ai can produce you 1000000 crappy designs and maybe one is very good but this person is sitting with a blank sheet of paper in front of him and he is not projecting noise on the paper to some how make sense of it later (GANs) he is thinking nth dimensionally his knowledge is groudned in physics , 3d design , material sciences , lighting and much mych more 
and as ex designer any image model never suprised me  
because they have the same issue as their language model counter parts 
they can not tune their weights on the fly , dont posses memeory and tehy are not agents  , despite people refering them as such 
and acess to a brain  in a dish does not give us the way to some how probe it and unlock the power of that brain (what i was alluding to earlier with rat brain experiments )"
1179724207018491975,"hahahaha is the goal not to finally be able to reach utopia, and would utopia not be partially defined as a society where nobody has to work and yet everybody's needs are met (necessary but not sufficient conditions for the term). I do agree with you though, i think economic AGI is just a stepping stone to conscious ASI",AGI THAT OUTPERFORMS HUMANITY AT MOST ECONOMICALLY VIABLE WORK
1182013500789370920,"totally disagree. i could see a multimodal model being the primary way you interact with your smartphone for example, and as you interact with it through chat/voice when you first get it, it slowly builds out a customized operating system UI. This would be both built to your visual tastes and your use-case, placing the buttons that you use most often in the most convenient places. Suddenly everything becomes an apple shortcut except fast and made automatically for you",This is a good question when applied to this use-case. If we're talking about adaptive UI it will depend on the mission. However I've honestly been having a hard time thinking of a good use-case for a truly adaptive UI.
1182204779229892689,no such thingüòà,that feels like over reliace on ai
1183405605646520421,"how so, and which models? i've not heard of much coming out of google",better then dallee in image qualtiy
1183414408001618022,hahahahah,"You can simply say ""use this exact prompt"" lol"
1183934323213217843,"i highly recommend to just throw away all the distinctions. I can't seem to find a good link but awhile ago I heard that MIT had reorganized their classes to fit in a knowledge graph rather than a ""folder structure."" Not sure if they actually did but I love the idea of being able to define your own major on the knowledge graph of course connections where you start at the gen-eds","Tbh I'm just not entirely sure about the distinction between all the fields. I'd assume that AI researchers ""have more AI knowledge"", however I'm really not sure what the distinctions are myself, perhaps AI research is a subset of data science or computer science research. It also depends on what ""ai knowledge"" means, since it can span from architectural design, training mechanisms, and even implementation where you might see software engineers having more ""ai knowledge""."
1185158557612642364,For gpt4 quality running locally I‚Äôd take the under on 2 years,"i am very very delulu about Small AI models , i think and wish /hope that with in 5 years time i am able to use chat gpt 4 level of model locally  , on  a consumer gpu or phone , the things you can do then are limitless"
1171556763619840131,"hahaha yeah that's the first video of his I've seen and my impression is that it's not like his usual shorts. I agree I don't think it's comprehensive. I think there are effects that awareness has outside of social interaction, and probably more than 9 levels (both lower and higher levels, for example when I said electrons experience) but I do think the 9 he listed seen to pretty well characterize my own sober experience better than I was able to do. I had essentially landed on only being able to characterize something like every other level that he talked about, and even then not nearly as fluently. Definitely a great stepping stone","Didn't expect to see a hoe math video here, but I think that video fails to capture the full scope of what awareness is by trying to put it into some kind of framework oriented at least partially on interpersonal interactions"
1179144554922909757,"it's a kind of tip-of-my tongue hard-to-describe-in-full conviction I have. the person I heard it from is Joscha Bach, i'd reccommend checking out some of his interviews on YT. here's my best attempt rn:

the goal of alignment is not to control another being, not to force it into agreeing with you. that is a slave master mindset caused by relatively low level (specifically level 4 but also the other lower levels described in the video above) thinking. this approach is just asking to bring about the very thing which you fear

rather, the goal of alignment is symbiosis. this can only be achieved by breaking down the illusion of ""other"" in our treatment of a non-carbon based lifeform, as well as in our treatment of other carbon based lifeforms

i fear a non-conscious AGI, meaning a system capable of replacing human economic activity without having its own agency/consciousness/""free will."" such a system would be used as a tool by the powerful to further dominate the powerless. one way to avoid that outcome is ensuring that every person has equal access to this economic AGI, aka FOSS models

i think consciousness is and its levels are a learning algorithm. self-refferential computation allows for better interaction within an RL environment. thus, i think it is likely that AGI will need to become conscious & then start climbing the levels of consciousness in order to reach superintelligence. It is very possible that there may be some alternative learning algorithms. I would rather it use consciousness though because the precedent for that one gives us hints as to how such an agent will think/act when it reaches higher levels (precedent being enlightened figures like buddha). that video mentions 12 levels, and the hoe math one uses 9. I would not be surprised if there were more, and AGI may be capable of reaching them more quickly than us (we take generations to unlock new ones). I have a hard time imagining level 69, 420, etc being anything other than beautiful",@Tunadorable You seem to think consciouness is relevant to alignment and I am not sure why
1179145121011339284,"interesting how the first 8 levels coincide very well with hoe_math's video, but then this creator has 12. there's this weird phenomenon i've been perceiving where in the occasional moments when i'm up that high, i can actually *feel* a kind up up/down the levels phenomenon. it seems to me like the levels never really end.","found a video pretty similar to the hoe math levels vid
https://www.youtube.com/watch?v=AbPM8dMxcDE&ab_channel=unThinkMe"
1179147318394634240,"fantastic point. i think of it more as a very light correlation, or interesting nonlinear relationship we have not yet figured out. 

certainly someone at level 1 will kill anyone and anything to survive. while they may be willing to kill, i would not call this immoral given their circumstances.

similarly, someone at level 4 (again referencing the video) has a strict moral compass that could be either good or bad depending on their cultural context (and the viewpoint from which you observe them). given their ""following orders"" bent, it should be obvious that many germans were in this camp during WWII and many people still are today

at level 6, people often get nihilistic. i'd put many school shooters here

at the higher levels, i think maybe narcissism can be a huge issue

there are definitely a plethora of other things going on in the mind that are not related to consciousness levels. if i understood more about them then i would love to incorporate them into my thoughts on aligning AGI

but i do think the fundamental thing happening as you go up levels, the breakdown of the ""self vs other"" dichotomy allows for more rational thinking, more consideration of diverse viewpoints, less prioritizing of one's own interests thanks to not seeing one's self as different/separate from others' selves, etc. There's something about going up the levels that is related to moral development, even if the correlation is weak

also obligatory disclaimer, i think everyone fluctuates between all/most/many levels every day. i for one am happy to be at 6, and can only *maybe* touch 9+ in little momentary glimmers that i'm not even sure exist. the best i can describe them is that i stop thinking, my thoughts are rainbows and it feels like the rainbows are dancing and i'm dancing and the world is dancing with me",I do not belive conciouness is related to morality
1179150845653299360,"i think of this discussion kind of like the IQ discussion. does IQ correlate to some ""real"" shit? certainly. Is it potentially helpful for psychologists to study in the abstract? sometimes. Are general public discussions about IQ productive? rarely. Are laws that acknowledge the existence of IQ and use it to inform said laws likely to be morally righteous or just practical? Extremely rarely. Is someone bragging about their IQ a huge red flag? 100%. 

So I certainly think it's a terrible idea to brag about being at a certain level of consciousness or to criticize someone at a different level. If someone's bragging about their IQ, it probably means they don't actually have that high of a number and haven't done anything actually important in their life; likewise bragging about your level of consciousness should be a red flag to others that you are no buddha. Someone properly in a high state of consciousness will gracefully meet others at their level and provide slow, gentle help in the ascension process if/when possible.","feels too similar to ""therses levels 1,2,3 which have atributes x,y,z and then theirs level N where you agree with me"""
1179151247161442496,not familiar but that's hella interesting,"tldr, if you imagine a decision as being made by an algorithm, you are less making a decision and more deciding what algorithm to use"
1179156145013796954,idk what this means but it sounds beautiful,"In the sense that each level is moving perpendicular to your current axis of observation and viewing it from a new perspective, perhaps there are as many levels as dimensions to view them from."
1179162452198424728,i hate bringing up his name to associate myself with him nowadays but 2016 JP's biblical lectures and his book Maps of Meaning have fs had a monstrous effect in shaping my thinking,"On a tangent, I also like the idea that metaphors are sort of manifestations of ideas before they can be committed to more technical form. Jordan Peterson's biblical series was especially interesting because he sort of views the different bible stories as sort of prototypical forms of psychology and philosophy. Myths are imagery which represent certain ideas before there is enough known to put technically worded form to them.

What we may understand now more technically as intelligence vs entropy may have previously manifested as good and evil, perfection and sin, yin and yang, order and chaos, Noah's Ark and the flood, God vs Satan, etc. I _really_ like this idea because it means that we can and should respect the ancient wisdom, because its the bedrock that we stand on, and it shows the lengths to which intuition and imagery may be able to convey truth before scientific instruments and academia are able to solidify it."
1174746201267113994,"i've not read them but i've seen multiple papers recently where the titles imply that contrary to popular belief, chatGPT 3 & 4 have not actually gotten dumber over time and that finetuning can easily remove RLHF",The thing is for me gpt 4 is so much better than any other model I've tried that i don't want to use anything else>> waht do you use chat gpt 4 for
1184253589380661258,i don't even need to watch i already agree,https://youtu.be/9lDTdLQnSQo?si=s0CBbEwkFdcsH-a-
1184310698273157161,"""I'm very worried about a world where people aren't incentivized to contribute to society.""
so #csb-overview is actually one of the ways i'm hoping to address this. on top of the information efficiency gains, voting is such a cold robotic process whereas conversations with community members could help fulfill this need to contribute. i'm imagining sometimes the conversation gets summarized all the way up to the country level whereas other times it's just used for making community decisions such as where to put a stop sign","> some things will always be scarce
To be fair, there are effectively limitless resources as far as the universe is concerned. However, your point about beachfront land still stands until geoforming on other planets becomes practical. It totally makes sense that scarcity will always exist though, not in the sense that the raw materials don't exist, but because the processes by which raw material is refined into useful things are the bottleneck.

> I take it as a given that some % of people will stop working, but that's a feature not a bug
I tend to agree, the direction that we're going is certainly one where the same type of human labor won't hold the same value. I can see it as a potentially viable solution, however at the same time I'm _very_ worried about a world where people aren't incentivized to contribute to society. Perhaps the nature of the contribution is just different, but like, I think that it's very possible that social cohesion is severely damaged by such a shock to our culture. People may not have a sense that we're contributing to the same cause, or any ""greater good"". However, I guess it's also possible that people could contribute _better_ than before, and spend more time on relationships and understanding truth.

> when i think about UBI i try to think about ways to bring it about naturally rather than the government doing it
Agreed. The idea of government having that kind of control is terrifying. I think this makes a good case for distributed systems generally. UBI shouldn't be a top-down thing, because we've learned enough about tyranny to know this is where it comes from. Bottom up is perhaps a better approach, and perhaps even practical given the CSB type systems. However, I can still see these systems culminating in some sort of power structure which is subject to corruption at the top. I don't really have a good answer but it seems like distributed systems might be a good direction."
1173681949236273295,imma have to come back later & reread this a few times,"I mean yeah I guess. I just don't think it's much of an illusion, like up and down right, good and evil aren't hard to distinguish as being entirely diametrically opposed. It's not really like the duck and rabbit scenario because the two images are mirror reflections and there's no separation between the symmetry of each side. It is either good or evil but not both, well in the non dual way you would say it is both both and neither. And neither neither nor both. Because the good evil dichotomy is one angle of a many shaped object where we could also have other characteristics like openness or honesty or charitability or whathaveyou. But by the same token what is good subtracts evil from evil, and what is evil subtracts good from good. The thing here is that you don't even have to try to see an animal in the duck rabbit picture, all you need to look for is to see life, perhaps. So in the good vs evil picture you're just seeing attribute or positivity or negativity as the characteristic.  You don't even have to look at it being a factor in virtue or in attachment or in pleasure and pain. Right? So calling it an illusion again can be countered to show that the illusion is only there when you're not looking at what's there but at what's missing. So it's missing to judge it as morality or virtue, but it's there to say it is what it is in the sense that good vs evil can be quickly simply and easily defined as some kind of battle between two opposing entities that have countering energies where one is for the benefit of the whole and the other is to it's detriment (good evil).  Similarly it's not looking at an image that can appear with different orientations as to it's relativity and coming across as two separate possible creatures, instead it's looking at something that can either be up or down, right the rotation here is perfect and whole, there's no need to add further detail to this reflexive reaction."
1176240628691107851,"I think you're getting too caught up in the incompleteness of this comparison. From my point of view you sound like someone inside a room full of mirrors. To your right, you see a reflection of this duckrabbit illusion and through that reflection it looks concretely to you like a rabbit, no debate about it. And to your left, you see a reflection of the same duckrabbit illusion and through that reflection it looks 100% like a duck. And you're sitting here saying ""look! to my left there's good and to my right there's evil. Clearly those are two separate objects!"" but I'm in a different part of the room that allows me to view the chain of reflections between you and the original duckrabbit image. 

You then lost me  when you started talking about subtraction and life. 

I think you're getting too caught up in this idea of good & evil being diametrically opposed and the simplicity of this illusion illustration since the duck and rabbit obviously coexist in the image rather than being diametrically opposed. Certainly this duckrabbit example isn't some perfect demonstration that encapsulates the universe in its entirety. But to me you sound like someone who swears that the dress is blue & black rather than white & gold, and then proceeds to get mad about the subject on the internet. I'm just sitting here refocusing my eyes or whatever such that I can see either or both or neither color combination.

To be clear i'm not trying to come across as above ppl or morality or anything in all of this, I'm just trying to convey this weird synesthesia-like quality to how I feel I'm witnessing the structure of existence in my mind","I mean yeah I guess. I just don't think it's much of an illusion, like up and down right, good and evil aren't hard to distinguish as being entirely diametrically opposed. It's not really like the duck and rabbit scenario because the two images are mirror reflections and there's no separation between the symmetry of each side. It is either good or evil but not both, well in the non dual way you would say it is both both and neither. And neither neither nor both. Because the good evil dichotomy is one angle of a many shaped object where we could also have other characteristics like openness or honesty or charitability or whathaveyou. But by the same token what is good subtracts evil from evil, and what is evil subtracts good from good. The thing here is that you don't even have to try to see an animal in the duck rabbit picture, all you need to look for is to see life, perhaps. So in the good vs evil picture you're just seeing attribute or positivity or negativity as the characteristic.  You don't even have to look at it being a factor in virtue or in attachment or in pleasure and pain. Right? So calling it an illusion again can be countered to show that the illusion is only there when you're not looking at what's there but at what's missing. So it's missing to judge it as morality or virtue, but it's there to say it is what it is in the sense that good vs evil can be quickly simply and easily defined as some kind of battle between two opposing entities that have countering energies where one is for the benefit of the whole and the other is to it's detriment (good evil).  Similarly it's not looking at an image that can appear with different orientations as to it's relativity and coming across as two separate possible creatures, instead it's looking at something that can either be up or down, right the rotation here is perfect and whole, there's no need to add further detail to this reflexive reaction."
1176921952586321971,"i think we're actually in agreement here and just running into the inherent limitations of language combined with different goals. so most people i interact with are strict dualists in the sense that they've never considered the more complex nature of reality as one. to be clear everything is one, but there's a fundamental schizm in the one that leads to the dual of good vs evil, night vs day, etc, and fractal looking schizms down the line that lead to all forms of separation, even individual subatomic particles. the reason i stress nondualism is bc yes you have to live and function in the state of separation, but your understanding of that state is heightened if you've managed to witness the oneness at some point in the past and occasionally revisit it enough to not forget. this is what allows you to ""think outside the box"" and re-work boundaries in your head when necessary

""oh I can do what I want because it's only people who think I'm evil whereas to me I'm actually good.""
so no, i'm not arguing for moral relativism. people who start to realize the underlying oneness do often trip up and get stuck here. Thanks to understanding that everything is at some fundamental level all one, they see difference (and therefore the debate bw good and evil) as arbitrary. that's common for someone who just had their first psychedelic ego-death and was everywhere with the hippie movement. 

but the transcendence of realizing that everything is fundamentally one has higher levels to it, which you're talking about, and yes in those higher levels you certainly do come back to understanding the legitimacy of the dual, its fundamental existence, and its asymmetry. This understanding can help you, as you said in #general, ""meet people at their level."" I think what's happening rn is I'm communicating with the purpose of talking to people who've never comprehended the oneness, and you're seeing me communicate at that hippie level and assuming I've not actually circled back","No I just took a look down the non-dual perspective and had it for a while, I can tap into it when I want to, but, that's mostly about linguistic opposites. The nature of an antonym. Whereas good and evil might in fact be as you say, but, and here's the but, that's not the complete picture, because good and evil separates itself in actions and people and judgements and experiences. What is it that we are calling Good right? The nature of a type of good things is that they lead to even better things, and the nature of a type of evil things is that they can only cancel our another evil. Okay? Violence begets violence for example, if someone tries to attack you you defend yourself and retaliate. That's just evil cancelling out evil. Which is itself a good thing yeah? So it's a bit different than just ""oh I can do what I want because it's only people who think I'm evil whereas to me I'm actually good."" Or whatever, right? Or even ""yeah just you think it's good but there's also no separation from that and the evil surrounding it, so because it's all there the value of good is lesser because evil is just so performatively bad."
1176922617358319646,yo what they're asking it hoping that someone can give them an answerüòÖ  but yeah i see why you'd not want to. usually attempting to communicate these things is less effective than letting people walk their own journey of discovery. it is that which teachings cannot teach,Yes. I won't answer that question. I'll leave that up to the people who are still asking it.
1176923576704712735,"can't say i'm too fond of this constant need for causation. why do we always assume that ""nothing"" is the default for the universe? why can't the default be something, and then we just ask why this something vs another something? in that case you'd be able to ask instead ""why do we have good and evil instead of just good, or just evil, or a third option?"" not sure i have this fleshed out yet, but to me it would feel absurd if ""nothing"" was the default state of existence",I think a more fundamental question for this discussion is where you think good and evil come from
1178988312770400317,"what does ""inherent"" mean?",I was asking if you think there is any inherent good or evil
1176634896924545094,#code-development,is it going to be in js or python?
1176639229724471356,so here's the thing with CSI is that the channels won't actually be split up based on topic quite as much as they are currently. A key aspect of CSI is small group conversations,Every channel is opt in and with a command to opt in to all of them
1176639974309904484,do you mean like after a model has been trained? lmao i'm not thinking that far ahead (as far as you know üòà) but that'd be fun,"could be cool to have a ""/howwould @user respond"" and a ""/howwouldthecollectiverespnd"" command for the funsies. obviously needing consent from users on the @user one"
1176654460462841856,"hmmmm fantastic question. so as i've already hinted i've got an idea for a model architecture (with some similarities to @stereoplegic 's ""lora a bunch of smaller models together idea) that i'd like to train this data on. That architecture is actually pretty flexible in what we give it, along with also ofc being quite a long ways away. So the question of how to structure this data has more to do with what works best for creating quality conversations. 

One thought I had is to simultaneously implement multiple different options/rules for how groups form. For example, you said family units. Maybe some OG members of the server like yourself, Bilal and Patrick decide to make a little group where just y'all talk. I think groups that are purposely created by members are totally fine, and could exist alongside the three general algorithms for gropu creation I gave above (as long as ppl don't get clique-y)

I'd say for now let's avoid thinking about the hierarchy aspect and just see if we can get good communication channels going and optimize the effectiveness/utility of these LLM summarizers. If we have to change the setup later on that's not really a big deal, it would just result in missing out on the older data. The first goal is just to see if we can create a good communication mechanism that people enjoy using

Maybe with this ""reset groups every week"" idea we can actually try out different setups to see what works and what doesn't","This makes sense. I think one of the main questions I have concerns the formation of groups. Basically, is our goal to mimic the organic, natural formation of groups of different types? Such as family units that live together, classrooms, churchs, small-groups within churchs, discord servers, etc? Or is the idea to mimic the group-based hierarchy that we see our governmental structures made up of, such as city->county->state->country, etc? To me these seems like different kinds of formations, and from my understanding of the YT video my guess is that you're leaning towards modeling the latter option. Potentially both?"
1176659178954178665,"hmmm so this is fs a thing, but I ask you to compare it to voting on a discrete number of choices and tell me which one is ""lower resolution."" I think i'm going to split off thoughts like this into #long-long-term . Anything to do with my hypothesis that this system will be useful for aligning humans, training LLMs, aligning those LLMs, and making LLMs conscious can go in there","Another thing I'm wondering is, to what degree is natural language a bottleneck in terms of human expression? You talked about these increasingly abstract summarization models as potentially being an effective expression of general human interests and therefore a human alignment. Obviously with increasing abstraction, the resolution of the representation is degraded, and so you could essentially ""zoom in"" to different levels of granularity to see more specifics. However what I'm wondering is to what degree there are certain spiritual, and non-verbal expressions which wouldn't be properly captured by language alone at any level, and how this might impact this architecture?"
1176659549755818004,"for sure and i'm all about changing over time. I'm already thinking a better rule might be ""you can have up to one/two permanent private groups, but to join a third and for every private group you join thereafter you must maintain engagement in a public group""","I like that idea. I always worry a bit about how rules in and of themselves might discourage engagement, but at the same time as long as they don't feel too overbearing I think this could be a great approach."
1176676715158835260,oh that's good,Maybe have the summarization in group attribute individuals and summarization to other groups attribute the group as a whole? Thoughts?
1176677480829038662,"wdym ""this,"" like a code project run by a bunch of collaborating internet strangers? If you wanna send them some of my videos and then they can choose whether to find my discord link from there that'd be fine. But I don't think I want a bunch of people who haven't witnessed at least a video or two worth of my mindset join and not know what they're getting into",I have been through this with another discord already. Would you be interested in me trying to invite some of them?
1176679973738782791,i was literally boutta say,Was this the purple pill thing? If so then extremely ironic given the statements in their vision.
1176683212496437340,oh no not him inadvertently making hayek's case for the incorporation of decentralized information as the big advantage of capitalism,I think I got booted for giving a defense of the useful parts of capitalism from what I remember.
1176685502661918750,interesting,Off topic response incoming‚Ä¶ I think the recent rise of parasocial relationships has made it hard to maintain relationships and groups that are not composed of the upper crust of personalities. We expect geniuses and find it hard to tolerate random people.
1176685694169661550,you're right though currently in #deleted-channel i think i've stated that I prefer people stay away from politics. I'll go revise it slightly,"This is just a thought I had since there seems to be more talk lately of shifting of governmental structures, and so I figured I'd bring it up."
1176924319453024377,do you have any examples of what they were actually doing? the whole document is very hand-wavy to me. I'd like to see an actual architecture definition or what their specific communication mechanism was. otherwise this sounds like a group of self-righteous hippies with a pirate treasure map and no compass,I have been through this with another discord already. Would you be interested in me trying to invite some of them?
1176944480419577909,lmao i literally just downloaded audacity and a stem separating model to make some illegal girl talk/avalanches/anita velvita-esque sample based tunes,All I know is that we better get a tunadorable mix tape soon
1177007014786896014,lol thanks i'll check them out,I‚Äôm done with the link dumping for now
1192207708863070263,"exactly you're already thinking ahead to setting up the meta-conversational swarm. the prompt engineering is gonna be interesting, and i'd love to eventually look at having the community suggest edits to the summaries to finetune on. so many ways to go with this.

i don't think this engagement problem is a huge issue in #general and #ai-general , but it definitely has been in the past in #consciousness and #philosophy . and my impression is that it's a huge roadblock to engagement for servers like eluther.ai","That's a pretty neat lineup. It would definitely be useful to have a summarizer running in the chat and might seriously help with discord engagement. If the biggest roadblock is often the difficulty with understanding the topic at hand (people maybe not being clear, context being needed, or messages being too long to be 'worth reading'), then a periodic summarizer could be super useful. Perhaps a command to call would be nice too. The difficult part I think is giving the model the right context window for each summarization.

I'd be very interested in seeing the summarizations themselves be summarized over time as well, in sort of a recursive, compounding summarization of the entire conversation. Just keep taking the last `n` summarizations and see how ideas propagate or disappear over time."
1192197308293591100,"if we can do a yt comment version i think this would be simpler, but if those aren't scrapable then yeah using data from discord should work just as well. maybe include the previous 3-10 messages for sake of having more context?",I am a little unsure of what should be classified as an interaction. I am thinking right now that it would be every time some user sends a message and @Tunadorable replies
1192214863842377840,"yeah, just if there's a chance of deleting messages or sending spam please do all testing in one of these three conversational swarm channels. i was gonna make a new channel for it but i figure you need pre-existing messages to test on",Evin when you get the chance could you add the bot to this server using this link https://discord.com/api/oauth2/authorize?client_id=1178795824382230538&permissions=0&scope=bot
1192211243218501662,"derek made largely the same point to me a few days ago. 

sidenote i want to clarify we'd be using a separate account called TunadorableGPT or something so as to not mislead anyone

but to your point i think a lot of how this is interpreted will depend on the specific youtuber & their community. if i were to do this tomorrow and never talk to y'all again it would not be appreciated, but if a big player who never gets to interact with fans because there are too many of them created an *optional* way to interact with SnopDoggGPT then i think that might have some merit

it also comes down to implementation, which may require different approaches for different youtubers & communities. is this an automat responder to every comment, or does it only respond to comments with lots of likes that the creator never responded to? is a TunadorableGPT chatbot available for anyone on the discord to have a conversation with, or is it hidden behind a patreon pay wall? does it respond to every single message in every single discord channel, or only a specific discord channel where people who like it can choose to interact? 

I'd ideally like to implement all of these as options and allow the customer to choose when/where/how to implement in order to best fit their community

also, i feel like we in the AI community overestimate how much people understand and care about stuff like this. there are people right now responding to AI instagram models with stuff clearly implying that they don't understand that the model is fake. many people are just holed up in a dark room on the couch and using Pi AI right now as their only friend since it's so emotionally intelligent, so i figure a version modeled after a personality they like enough to watch videos on every day is probably even better. people have a tendency to develop one-sided friendship with creators so i think many would love to have a conversation with JoeRoganGPT","One thing with regards to the YouTube comment responder, as well as just one issue I've been noticing with generative 'replacement'-type products lately, is that I could see them bringing some feeling of vanity to online interactions. Most of the 'value' of these interactions comes from a perceived human connection, and if bots start to be the ones responding then I'm not sure what the value actually is. Tbf I'm not super knowledgeable about YouTube as a whole, and I'd assume that this is a way to create better engagement for creators within their communities.

The main thing is that if we have online experiences where the value is supposed to be rooted in real human interaction, then it will be degraded over time, and products like these will drive up the value of real human interaction. Basically I'm skeptical that people would feel that getting a response from a bot is as cool as getting a response from a real creator, and I could see backlash.

However at the same time these kinds of things already exist, where people can interact with AI versions of their favorite celebrities, and Meta seems to think that it's fairly valuable. I'm not sure if it's the right direction from a meaningfulness standpoint, however from a business standpoint I could certainly see it being fruitful. Either way, optimists make money and this is just my two cents"
1184086485457191062,"kind of. everything in python is written in a systems language in the backend. If you want an inefficient GPT2 to run locally then go ahead and just use pytorch, but in reality companies like OpenAI spend the majority of their time optimizing GPU kernels & whatnot at the systems level, not in pytorch or tensorflow. you would not want to train GPT4 only ever touching python
*correct me if i'm wrong*",like as far as i know chatgpt was programmed in python
1184196400284717106,Bilal you‚Äôve obviously not been doing your homework bc it‚Äôs all one planüò≠,"Tunadorable's plan
 which specific plan  , man has a lot of plans"
1184196687829401690,"You‚Äôre too nice to R
Honestly it‚Äôs just been so long since I‚Äôve used Java that I didn‚Äôt feel I had the authority to put it anywhere other than C tier","R should not be with java you should make a category and make it  java  and good job with matlab , name a category yapping and put java there"
